{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pharser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8mm67u1l7b31GepCWy9Ko",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakitha/Unstractured_PDF_DATA/blob/master/pharser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A10GEkpHdAuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7a15a1c-570a-4607-ffb6-82c02cae3264"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Version: \", tf.__version__)\n",
        "import tensorflow_addons as tf_ad\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFIfYUrIeRrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFD(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super(FFD, self).__init__()\n",
        "\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs, dropout_vec):\n",
        "    \n",
        "    inputs = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs).numpy()# replace nan with zeros\n",
        "    dropout_vec = tf.convert_to_tensor(dropout_vec, dtype= inputs.dtype)\n",
        "\n",
        "    i = tf.math.multiply(inputs, dropout_vec)\n",
        "    x = self.dense1(i)\n",
        "    \n",
        "    return self.dense2(x)\n",
        "\n",
        "\n",
        "class NerModel(tf.keras.Model):\n",
        "  def __init__(self, hidden_num, label_size):\n",
        "    super(NerModel, self).__init__()\n",
        "\n",
        "    self.ffd = FFD()\n",
        "\n",
        "    self.num_hidden = hidden_num\n",
        "    self.label_size = label_size\n",
        "\n",
        "    self.biLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_num, input_shape=(4,), return_sequences=True), )\n",
        "      \n",
        "    self.dense = tf.keras.layers.Dense(label_size,activation='softmax')\n",
        "\n",
        "    self.transition_params = tf.Variable(tf.random.uniform(shape=(label_size, label_size)))\n",
        "\n",
        "\n",
        "  def call(self,inputs,labels=None,training=None):\n",
        "    \n",
        "    outputs = []\n",
        "\n",
        "\n",
        "    for time_step in range(inputs.shape[2]-1):\n",
        "  \n",
        "      input = inputs[:, time_step, :]\n",
        "      dropout_vec = 1 - np.isnan(input).astype(np.int)\n",
        "\n",
        "      ffd_output = self.ffd(input, dropout_vec)\n",
        "      \n",
        "      outputs.append(ffd_output)\n",
        "\n",
        "    logits = tf.stack(tf.unstack(tf.stack(outputs,axis = 0),axis=1),axis=0)\n",
        "\n",
        "      \n",
        "    #text_lens = tf.math.reduce_sum(tf.cast(tf.math.not_equal(inputs, 0), dtype=tf.int32), axis=-1)\n",
        "\n",
        "    if labels is not None:\n",
        "      \n",
        "      label_sequences = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
        "      log_likelihood, self.transition_params = tf_ad.text.crf_log_likelihood(logits,label_sequences,[3,3],transition_params=self.transition_params))\n",
        "      \n",
        "      return logits, text_lens, log_likelihood\n",
        "    else:\n",
        "\n",
        "      return logits, text_lens\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG0CtVPc425y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = NerModel(hidden_num = args.hidden_num, vocab_size = len(vocab2id), label_size= len(tag2id), embedding_size = args.embedding_size)\n",
        "model = NerModel(hidden_num = 1, label_size= 3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS878LLf4ZXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_step(inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "      logits, text_lens= model(inputs, targets, training=True)\n",
        "      loss = - tf.reduce_mean(logits)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss,logits, text_lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjmDcDp24JcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99123bbd-b4cf-4e4a-d3cf-ad45f75443ed"
      },
      "source": [
        "## Note: Rerunning this cell uses the same model variables\n",
        "inputs = np.asarray([[[.1,.2,.3,.4],[.1,.2,.3,.4],[.1,.2,.3,.4]],[[.1,.2,.3,.4],[.1,.2,.3,.4],[.1,.2,.3,.4]]], dtype=np.float32)\n",
        "\n",
        "targets   = np.asarray([[1,2,2],[1,6,2]])\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 32\n",
        "  \n",
        "    # Optimize the model\n",
        "  loss, logits, text_lens = train_one_step(inputs, targets)\n",
        "  #logits, text_lens = train_one_step(inputs, targets)\n",
        "\n",
        "    # Track progress\n",
        "  epoch_loss_avg.update_state(loss)  # Add current batch loss\n",
        "    # Compare predicted label to actual label\n",
        "    # training=True is needed only if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "  #epoch_accuracy.update_state(targets, model(inputs, training=True))\n",
        "\n",
        "  # End epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())s=self.transition_params\n",
        "  #train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  \n",
        "  print(\"Epoch {:03d}: Loss: {:.3f}\".format(epoch,epoch_loss_avg.result()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0f03b3056b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m#logits, text_lens = train_one_step(inputs, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-ef2fd3b48c94>\u001b[0m in \u001b[0;36mtrain_one_step\u001b[0;34m(inputs, targets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lens\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-4a5a3d5e75c8>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, labels, training)\u001b[0m\n\u001b[1;32m     24\u001b[0m             log_likelihood, self.transition_params = tf_ad.text.crf_log_likelihood(logits,\n\u001b[1;32m     25\u001b[0m                                                                                    \u001b[0mlabel_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                                                                    \u001b[0mtext_lens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                                                                                    )\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36mcrf_log_likelihood\u001b[0;34m(inputs, tag_indices, sequence_lengths, transition_params)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     sequence_scores = crf_sequence_score(inputs, tag_indices, sequence_lengths,\n\u001b[0;32m--> 195\u001b[0;31m                                          transition_params)\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mlog_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_log_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36mcrf_sequence_score\u001b[0;34m(inputs, tag_indices, sequence_lengths, transition_params)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     return tf.cond(\n\u001b[0;32m---> 67\u001b[0;31m         tf.equal(tf.shape(inputs)[1], 1), _single_seq_fn, _multi_seq_fn)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond_for_tf_v2\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m   \"\"\"\n\u001b[0;32m-> 1392\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrue_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mcond\u001b[0;34m(pred, true_fn, false_fn, strict, name, fn1, fn2)\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_UnpackIfSingleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36m_multi_seq_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_multi_seq_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Compute the scores of the given tag sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0munary_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrf_unary_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         binary_scores = crf_binary_score(tag_indices, sequence_lengths,\n\u001b[1;32m     62\u001b[0m                                          transition_params)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_addons/text/crf.py\u001b[0m in \u001b[0;36mcrf_unary_score\u001b[0;34m(tag_indices, sequence_lengths, inputs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     unary_scores = tf.reshape(\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_tag_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         [batch_size, max_seq_len])\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, validate_indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   4539\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4540\u001b[0m       \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4541\u001b[0;31m       batch_dims=batch_dims)\n\u001b[0m\u001b[1;32m   4542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4524\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_v2\u001b[0;34m(params, indices, axis, batch_dims, name)\u001b[0m\n\u001b[1;32m   3753\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3754\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3755\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3756\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3757\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[4] = 18 is not in [0, 18) [Op:GatherV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHIsPjzju2oO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "55c825e9-3565-4efe-fb93-52891b8db6ae"
      },
      "source": [
        "inputs = np.asarray([[[.1,.2,.3,.4],[.1,.2,.3,.4],[.1,.2,.3,.4]]], dtype=np.float32)\n",
        "\n",
        "biLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(2, return_sequences=True), )\n",
        "dense = tf.keras.layers.Dense(3,activation='softmax')\n",
        "\n",
        "logits = dense(biLSTM(inputs))\n",
        "print(logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[0.33443305 0.3122755  0.35329145]\n",
            "  [0.33616656 0.31302205 0.35081142]\n",
            "  [0.33652422 0.31749234 0.3459835 ]]], shape=(1, 3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn_gBDNklVEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.constant([[[.1,.2,.3,.4],[.1,.2,.3,.4],[.1,.2,.3,.4]]], dtype=np.float32)\n",
        "targets   = np.asarray([[1,2,0]])\n",
        " \n",
        "log_likelihood, transition_params = tf_ad.text.crf_log_likelihood(logits, targets,[3]) #[batch_size, max_seq_len]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHo2zLRp0cZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fd186fdd-4d41-4bb0-d7ce-465a45d2e3f4"
      },
      "source": [
        "inputs = tf.constant([[[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4]],[[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4]]])\n",
        "print(tf.shape(inputs))\n",
        "targets   = tf.constant([[1,2,0],[1,1,0]])\n",
        "print(tf.shape(targets))\n",
        "text_lens = [2,2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 3 4], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 3], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmIugWzEhh1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8f85a815-5e65-40c6-ff83-867cb643fb38"
      },
      "source": [
        "biLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(3, return_sequences=True), )\n",
        "dense = tf.keras.layers.Dense(3,activation='softmax')\n",
        "\n",
        "logits = dense(biLSTM(inputs))\n",
        "print(logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[0.37104094 0.31334856 0.31561047]\n",
            "  [0.35531765 0.32940105 0.3152813 ]\n",
            "  [0.33627197 0.34606826 0.31765977]]\n",
            "\n",
            " [[0.37104094 0.31334856 0.31561047]\n",
            "  [0.35531765 0.32940105 0.3152813 ]\n",
            "  [0.33627197 0.34606826 0.31765977]]], shape=(2, 3, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNOtK-8Jh0W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_likelihood, transition_params = tf_ad.text.crf_log_likelihood(logits, targets ,text_lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByylJ1ZbnM2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d77d1f18-1573-4442-bfa8-09876af511aa"
      },
      "source": [
        "inputs = tf.constant([[[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4]],[[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4],[ 0.1, 0.2, 0.3, 0.4]]])\n",
        "text_lens = tf.math.reduce_sum(tf.cast(tf.math.not_equal(inputs, 0), dtype=tf.int32), axis=-1)\n",
        "print(text_lens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[4 4 4]\n",
            " [4 4 4]], shape=(2, 3), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNs7bWigHqtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#biLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_num, input_shape=(4,), return_sequences=True), )\n",
        "#logits = dense(biLSTM(inputs))\n",
        "\n",
        "inputs = tf.constant([[[ 0.1, np.nan, 0.3, 0.4],[ 0.2, 0.3, 0.4, 0.4],[ 0.1, 0.4, 0.4, 0.4]],[[ 0.4, 0.2, 0.3, 0.4],[ 0.1, 0.4, 0.3, 0.4],[ 0.1, 0.2, 0.4, 0.4]]])\n",
        "\n",
        "class FFD(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super(FFD, self).__init__()\n",
        "\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs, dropout_vec):\n",
        "\n",
        "    inputs = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs).numpy()# replace nan with zeros\n",
        "    dropout_vec = tf.convert_to_tensor(dropout_vec, dtype= inputs.dtype)\n",
        "\n",
        "    i = tf.math.multiply(inputs, dropout_vec)\n",
        "    x = self.dense1(i)\n",
        "    \n",
        "    return self.dense2(x)\n",
        "\n",
        "\n",
        "ffd = FFD()\n",
        "\n",
        "outputs = []\n",
        "\n",
        "\n",
        "for time_step in range(inputs.shape[2]-1):\n",
        "  \n",
        "  input = inputs[:, time_step, :]\n",
        "  dropout_vec = 1 - np.isnan(input).astype(np.int)\n",
        "  #inputs[np.isnan(inputs)] = 0 #this should handle in the model.\n",
        "\n",
        "  ffd_output = ffd(input, dropout_vec)\n",
        "  outputs.append(ffd_output) #since batch sice is 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd94FmuduTPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cef047f6-75e3-4ae0-8e9b-85e42dabe8d9"
      },
      "source": [
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              " array([[       nan,        nan,        nan],\n",
              "        [0.3439042 , 0.3394569 , 0.31663895]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              " array([[0.35776103, 0.34707984, 0.2951592 ],\n",
              "        [0.3508219 , 0.34332076, 0.30585733]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              " array([[0.36040863, 0.34848273, 0.2911086 ],\n",
              "        [0.35815635, 0.3472904 , 0.2945532 ]], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7pmobJ32xbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = tf.stack(tf.unstack(tf.stack(outputs,axis = 0),axis=1),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5s4NDKkuptV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "targets   = tf.constant([[1,2,0]])\n",
        "text_lens = [3]\n",
        "log_likelihood, transition_params = tf_ad.text.crf_log_likelihood(logits, targets ,text_lens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR9GpoqaQPK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "475de69c-1c99-401c-8334-8bb2216f9fda"
      },
      "source": [
        "x = np.asarray([[np.nan, 1, 3]])\n",
        "#x = x[np.logical_not(np.isnan(x))]\n",
        "x = 1 - np.isnan(x).astype(np.int)\n",
        "\n",
        "x[np.isnan(x)] = 0\n",
        "#B.astype(np.int)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKyG1qrLj1Rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQc4Sz7ZpwLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.constant([[[ 0.1, np.nan, 0.0, 0.4],[ 0.2, 0.3, 0.4, 0.4],[ 0.1, 0.4, 0.4, 0.4]],[[ 0.4, 0.2, 0.3, 0.4],[ 0.1, 0.4, 0.3, 0.4],[ 0.1, 0.2, 0.4, 0.4]]])\n",
        "\n",
        "input = inputs[:, 0, :]\n",
        "dropout_vec = 1 - np.isnan(input).astype(np.int)\n",
        "\n",
        "dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "dense2 = tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "\n",
        "input = tf.where(tf.math.is_nan(input), tf.zeros_like(input), input).numpy()\n",
        "\n",
        "i = tf.math.multiply(input, tf.convert_to_tensor(dropout_vec, dtype= input.dtype))\n",
        "j = dense1(i)\n",
        "k = tf.math.multiply(j, tf.convert_to_tensor(dropout_vec, dtype=tf.float32))\n",
        "\n",
        "\n",
        "#x = j(i)\n",
        "\n",
        "#dense2(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxSvlk2avPE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fb418b7f-6ea6-4639-9f94-305c03e30b8d"
      },
      "source": [
        "x k \n",
        "  v\n",
        "l\n",
        "\n",
        "x,v,j,l\n",
        "\n",
        "model 1 = just a FFN, model 2 = lstm cell\n",
        "[[x_x, x_x, f_x, x_v, x_v, f_v, 0, 0, 0 ,x_l, x_l, f_l ],\n",
        "[x_x, x_x, f_x, x_v, x_v, f_v, 0, 0, 0 ,x_l, x_l, f_l ],\n",
        "[x_x, x_x, f_x, x_v, x_v, f_v, 0, 0, 0 ,x_l, x_l, f_l ],\n",
        "[x_x, x_x, f_x, x_v, x_v, f_v, 0, 0, 0 ,x_l, x_l, f_l ]]\n",
        "\n",
        "model 2 = lstm loop\n",
        "[[x_x, x_x, f_x, x_v, x_v, f_v, [0, 0, 0] ,x_l, x_l, f_l ],\n",
        "[x_x, x_x, f_x, x_v, x_v, f_v, [0, 0, 0],x_l, x_l, f_l ],\n",
        "[x_x, x_x, f_x, x_v, x_v, f_v, [0, 0, 0] ,x_l, x_l, f_l ],\n",
        "[x_x, x_x, f_x, x_v, x_v, f_v, [0, 0, 0] ,x_l, x_l, f_l ]]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
              "array([[0.1, 0. , 0. , 0.4],\n",
              "       [0.4, 0.2, 0.3, 0.4]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B5DdovC2W9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c2aec034-9c95-4997-ba16-f758e02a9a20"
      },
      "source": [
        "j"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
              "array([[0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.07846069, 0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cFx1O2e3rfn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "468189c9-0653-453c-8626-5ab75be96b0c"
      },
      "source": [
        "class FFD(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    \n",
        "    super(FFD, self).__init__()\n",
        "\n",
        "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(3, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs, dropout_vec):\n",
        "    \n",
        "    inputs = tf.where(tf.math.is_nan(inputs), tf.zeros_like(inputs), inputs).numpy()# replace nan with zeros\n",
        "    dropout_vec = tf.convert_to_tensor(dropout_vec, dtype= inputs.dtype)\n",
        "\n",
        "    i = tf.math.multiply(inputs, dropout_vec)\n",
        "    x = self.dense1(i)\n",
        "    \n",
        "    return self.dense2(x)\n",
        "\n",
        "\n",
        "class NerModel(tf.keras.Model):\n",
        "  def __init__(self, hidden_num, label_size):\n",
        "    super(NerModel, self).__init__()\n",
        "\n",
        "    self.ffd = FFD()\n",
        "\n",
        "    self.num_hidden = hidden_num\n",
        "    self.label_size = label_size\n",
        "\n",
        "    self.biLSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_num, input_shape=(4,), return_sequences=True), )\n",
        "      \n",
        "    self.dense = tf.keras.layers.Dense(label_size,activation='softmax')\n",
        "\n",
        "    self.transition_params = tf.Variable(tf.random.uniform(shape=(label_size, label_size)))\n",
        "\n",
        "\n",
        "  def call(self,inputs,labels=None,training=None):\n",
        "    \n",
        "    outputs = []\n",
        "\n",
        "\n",
        "    for time_step in range(inputs.shape[2]-1):\n",
        "  \n",
        "      input = inputs[:, time_step, :]\n",
        "      dropout_vec = 1 - np.isnan(input).astype(np.int)\n",
        "\n",
        "      ffd_output = self.ffd(input, dropout_vec)\n",
        "      \n",
        "      outputs.append(ffd_output)\n",
        "\n",
        "    logits = tf.stack(tf.unstack(tf.stack(outputs,axis = 0),axis=1),axis=0)\n",
        "\n",
        "      \n",
        "    #text_lens = tf.math.reduce_sum(tf.cast(tf.math.not_equal(inputs, 0), dtype=tf.int32), axis=-1)\n",
        "\n",
        "    if labels is not None:\n",
        "      \n",
        "      label_sequences = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
        "      log_likelihood, self.transition_params = tf_ad.text.crf_log_likelihood(logits,label_sequences,[3,3],transition_params=self.transition_params))\n",
        "      \n",
        "      return logits, text_lens, log_likelihood\n",
        "    else:\n",
        "\n",
        "      return logits, text_lens\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
              "array([[0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.07846069, 0.        ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39AcA5LJBouj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "7fab72af-432e-4127-d433-1476060543a9"
      },
      "source": [
        "samples, timesteps, features = 2, 10, 8\n",
        "inputs = np.random.random([samples, timesteps, features]).astype(np.float32)\n",
        "inputs[:, 3, :] = 0.\n",
        "inputs[:, 5, :] = 0.\n",
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.30563   , 0.8578603 , 0.09359249, 0.45120567, 0.80962515,\n",
              "         0.80292475, 0.718621  , 0.72389615],\n",
              "        [0.76597154, 0.51600266, 0.6955795 , 0.15295061, 0.17176181,\n",
              "         0.39968657, 0.77693236, 0.4316625 ],\n",
              "        [0.8949149 , 0.4862184 , 0.69731045, 0.89588296, 0.44410047,\n",
              "         0.7779092 , 0.3695223 , 0.70633113],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.08722161, 0.45591286, 0.76407033, 0.6093148 , 0.35731044,\n",
              "         0.98193914, 0.0062343 , 0.30492923],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.85145736, 0.56486636, 0.20516314, 0.5360692 , 0.856764  ,\n",
              "         0.28055114, 0.23640926, 0.1716804 ],\n",
              "        [0.937895  , 0.07445275, 0.58404136, 0.08941504, 0.2051817 ,\n",
              "         0.7395205 , 0.09835254, 0.29336497],\n",
              "        [0.10854036, 0.62597597, 0.8276086 , 0.00956349, 0.4365472 ,\n",
              "         0.40281162, 0.44428992, 0.34712523],\n",
              "        [0.5733852 , 0.534496  , 0.8069402 , 0.08590777, 0.23358174,\n",
              "         0.04514689, 0.6658675 , 0.02070244]],\n",
              "\n",
              "       [[0.1298568 , 0.56381243, 0.4310224 , 0.14335431, 0.25730285,\n",
              "         0.30739713, 0.14721784, 0.6476735 ],\n",
              "        [0.60204506, 0.5671901 , 0.61487836, 0.81981593, 0.71425384,\n",
              "         0.5511446 , 0.00423942, 0.87195003],\n",
              "        [0.06332026, 0.147606  , 0.39404798, 0.33390924, 0.69575983,\n",
              "         0.56590056, 0.55701673, 0.4854069 ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.14733562, 0.81168044, 0.7393238 , 0.7530308 , 0.0188671 ,\n",
              "         0.16226186, 0.8758448 , 0.26282388],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        ],\n",
              "        [0.991843  , 0.6498204 , 0.2073664 , 0.5881317 , 0.8390831 ,\n",
              "         0.55470365, 0.432264  , 0.72017765],\n",
              "        [0.89510274, 0.19599614, 0.2477364 , 0.15109846, 0.60413826,\n",
              "         0.2590763 , 0.49860007, 0.96428907],\n",
              "        [0.23118372, 0.8510225 , 0.6248624 , 0.6137115 , 0.1417668 ,\n",
              "         0.2023519 , 0.9608909 , 0.8667318 ],\n",
              "        [0.94749326, 0.11679389, 0.40498206, 0.03856787, 0.97105473,\n",
              "         0.55422074, 0.83368003, 0.31514746]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hJ5-4UZgHhy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}