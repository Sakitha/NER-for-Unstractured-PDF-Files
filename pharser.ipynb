{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pharser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3KGHxdi8IBqPtvXe+7XhN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakitha/Unstractured_PDF_DATA/blob/master/pharser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A10GEkpHdAuz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04b02934-597a-4192-d6e2-9ea3d832a0f5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Version: \", tf.__version__)\n",
        "import tensorflow_addons as tf_ad\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO5ddIAfpeLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3a41970e-131d-4e58-a23d-f0b923720173"
      },
      "source": [
        "'''\n",
        "lets say a sample cv has the following format;\n",
        "\n",
        "X K \n",
        "  V\n",
        "L\n",
        "\n",
        "if we choose following words to be our corner words,  \n",
        "corner_words = X,V,J,L\n",
        "\n",
        "features ->\n",
        "\n",
        " ------X-----    ------V-----    ------J-----  ------L-----\n",
        "[[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ],\n",
        "[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ],\n",
        "[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ],\n",
        "[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ]]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nlets say a sample cv has the following format;\\n\\nX K \\n  V\\nL\\n\\nif we choose following words to be our corner words,  \\ncorner_words = X,V,J,L\\n\\nfeatures ->\\n\\n ------X-----    ------V-----    ------J-----  ------L-----\\n[[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ],\\n[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ],\\n[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ],\\n[x_X, y_X, f_X, x_V, x_V, f_V, x_J, y_J, f_J ,x_L, y_L, f_L ]]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFIfYUrIeRrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NerModel(tf.keras.Model):\n",
        "    def __init__(self, hidden_num, label_size):\n",
        "        super(NerModel, self).__init__()\n",
        "\n",
        "        self.num_hidden = hidden_num\n",
        "        self.label_size = label_size\n",
        "\n",
        "        self.dense1 = tf.keras.layers.Dense(hidden_num, activation=tf.nn.relu)\n",
        "        self.dense2 = tf.keras.layers.Dense(100, activation=tf.nn.relu)\n",
        "        self.dense3 = tf.keras.layers.Dense(label_size, activation=tf.nn.softmax)\n",
        "        self.transition_params = tf.Variable(tf.random.uniform(shape=(label_size, label_size)))\n",
        "\n",
        "    def call(self, inputs, labels=None, training=None):\n",
        "        ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, infer_shape=False)\n",
        "        word_count = inputs.shape[1]\n",
        "\n",
        "        for time_step in range(word_count):\n",
        "            input = inputs[:, time_step, :]\n",
        "            x1 = self.dense1(input)\n",
        "            x2 = self.dense2(x1)\n",
        "            ffd_output = self.dense3(x2)\n",
        "            ta = ta.write(time_step, ffd_output)\n",
        "\n",
        "        logits = tf.transpose(ta.stack(), [1, 0, 2])\n",
        "        if labels is not None:\n",
        "            label_sequences = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
        "            log_likelihood, self.transition_params = tf_ad.text.crf_log_likelihood(logits, label_sequences,\n",
        "                                                                               [word_count],\n",
        "                                                                               transition_params=self.transition_params)\n",
        "            return logits, [word_count], log_likelihood\n",
        "        else:\n",
        "            return logits,[word_count]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS878LLf4ZXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_step(text_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits, text_lens, log_likelihood = model(text_batch, labels_batch, training=True)\n",
        "        loss = - tf.reduce_mean(log_likelihood)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss, logits, text_lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNrMGSEFqXPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_acc_one_step(logits, text_lens, labels_batch):\n",
        "    paths = []\n",
        "    accuracy = 0\n",
        "    y_real = []\n",
        "    for logit, text_len, labels in zip(logits, text_lens, labels_batch):\n",
        "        viterbi_path, _ = tf_ad.text.viterbi_decode(logit[:text_len], model.transition_params)\n",
        "        paths.append(viterbi_path)\n",
        "        if type(labels) is np.ndarray:\n",
        "            y_real.append(list(labels[:text_len]))\n",
        "        else:\n",
        "            y_real.append(list(labels.numpy()[:text_len]))\n",
        "\n",
        "        correct_prediction = tf.equal(\n",
        "            tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences([viterbi_path], padding='post'),\n",
        "                                 dtype=tf.int32),\n",
        "            tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences([labels[:text_len]], padding='post'),\n",
        "                                 dtype=tf.int32)\n",
        "        )\n",
        "\n",
        "        accuracy = accuracy + tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    accuracy = accuracy / len(paths)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5gvBVTiqeGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3d313c2d-467f-4b5c-b799-6d297c80c777"
      },
      "source": [
        "inputs = np.asarray([[[.1,.2,.3,.4],[.1,.2,.3,.4],[.1,.2,.3,.4]]], dtype=np.float32)\n",
        "targets   = np.asarray([[1,2,2]])\n",
        "\n",
        "model = NerModel(hidden_num=512, label_size=3)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss, logits, text_lens = train_one_step(inputs, targets)\n",
        "    accuracy = get_acc_one_step(logits, text_lens, targets)\n",
        "    print('epoch %d, loss %.4f , accuracy %.4f' % (epoch, loss, accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, loss 3.7015 , accuracy 0.0000\n",
            "epoch 1, loss 3.4594 , accuracy 0.0000\n",
            "epoch 2, loss 3.1747 , accuracy 0.3333\n",
            "epoch 3, loss 2.9630 , accuracy 0.3333\n",
            "epoch 4, loss 2.8838 , accuracy 0.3333\n",
            "epoch 5, loss 2.8512 , accuracy 0.3333\n",
            "epoch 6, loss 2.8259 , accuracy 0.3333\n",
            "epoch 7, loss 2.8016 , accuracy 0.3333\n",
            "epoch 8, loss 2.7776 , accuracy 0.3333\n",
            "epoch 9, loss 2.7538 , accuracy 0.3333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hJ5-4UZgHhy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}